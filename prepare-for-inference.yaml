apiVersion: batch/v1
kind: Job
metadata:
  name: {STORY_ID}-prepare-for-inference
spec:
  backoffLimit: 0
  ttlSecondsAfterFinished: 0
  template:
    spec:
      containers:
        - name: prepare-for-inference
          image: us.gcr.io/$ARTEFACTS_PROJECT_NAME/speech-to-landmarks
          command: ["bash", "-c",
                    "mkdir /data && \
                     mkdir /models && \
                     gcsfuse \
                       --only-dir {STORY_ID} \
                       $GENERATED_BUCKET_NAME \
                       /data && \
                     gcsfuse \
                       --implicit-dirs \
                       $MODELS_BUCKET_NAME \
                       /models && \
                     python3 prepare_for_inference.py && \
                     gcloud pubsub topics publish completed-prepare-for-inference \
                       --message \"{STORY_ID}\""]
          workingDir: /app
          securityContext:
            privileged: true
            capabilities:
              add:
                - SYS_ADMIN
          resources:
            limits:
              cpu: "$NUM_CPUS"
      restartPolicy: Never
