apiVersion: batch/v1
kind: Job
metadata:
  name: {STORY_ID}-prepare-for-inference
spec:
  backoffLimit: 0
  ttlSecondsAfterFinished: 0
  template:
    spec:
      containers:
        - name: prepare-for-inference
          image: us.gcr.io/$ARTEFACTS_PROJECT_NAME/speech-to-landmarks
          command: ["bash", "-c",
                    "echo prepare-for-inference `date` >> /data/events.log && \
                     mkdir /models && \
                     gcsfuse \
                       --implicit-dirs \
                       $MODELS_BUCKET_NAME \
                       /models && \
                     python3 prepare_for_inference.py && \
                     gsutil -m rsync -r /data gs://${GENERATED_BUCKET_NAME}/{STORY_ID} && \
                     gcloud pubsub topics publish completed-prepare-for-inference \
                       --message \"{STORY_ID}\" && \
                     echo prepare-for-inference `date` >> /data/events.log"]
          workingDir: /app
          securityContext:
            privileged: true
            capabilities:
              add:
                - SYS_ADMIN
          resources:
            limits:
              cpu: "$NUM_CPUS"
          volumeMounts:
            - name: data
              mountPath: /data
              subPath: {STORY_ID}
      restartPolicy: Never
      volumes:
        - name: data
          hostPath:
            path: /mnt/disks/ssd0
